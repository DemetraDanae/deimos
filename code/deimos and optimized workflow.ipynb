{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "start_CPU = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from deimosFunction import deimos\n",
    "from Kennard_Stone import kenStone\n",
    "from core_function import deimos_core\n",
    "from deimos_test import deimos_1D_test\n",
    "from clustering_function import clust\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from validation import q2ext\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip install mip\n",
    "#from mip import Model, xsum, minimize, BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"C:/Users/Dimitra/data.csv\"\n",
    "data = pd.read_csv(data_file, header=0, sep=\";\", index_col=0)\n",
    "\n",
    "X = data.iloc[:, 1:len(data.columns)]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "# Scaling\n",
    "X_scaled = (X - X.min()) / (X.max() - X.min())\n",
    "y_scaled = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "# Splitting into train-test\n",
    "#from sklearn.model_selection import train_test_split # in case of random splitting\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X_scaled, y_scaled, train_size=0.66, random_state=8867453315) #Random\n",
    "\n",
    "# Kennard-Stone\n",
    "X_train, X_test, y_train, y_test = kenStone(X_scaled, y_scaled, train_ratio=0.66)\n",
    "\n",
    "samples_train = y_train.count()  # number of train samples\n",
    "samples_test = y_test.count() # number of test samples\n",
    "features = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression for one region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression (R=1)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_score = lr.score(X_train, y_train)\n",
    "lr_test_score = lr.score(X_test, y_test)\n",
    "\n",
    "coeffLR = lr.coef_\n",
    "interceptLR = lr.intercept_\n",
    "\n",
    "predictionsLR = pd.DataFrame(lr.predict(X_test), index=X_test.index, columns=['Prediction'])\n",
    "y_hat_lr = lr.predict(X_train)\n",
    "RMSE_lr = sqrt(mean_squared_error(y_train, y_hat_lr))\n",
    "r_lr = np.corrcoef(y_train, y_hat_lr)\n",
    "R2lr = r_lr[0][1]**2\n",
    "\n",
    "y_hat_test_lr = pd.DataFrame(lr.predict(X_test), index=X_test.index, columns=['Prediction'])\n",
    "RMSE_test_lr = sqrt(mean_squared_error(y_test, y_hat_test_lr))\n",
    "q2lr = q2ext(y_test, predictionsLR, y_train)\n",
    "print(\"RMSE linear regression\", RMSE_lr)\n",
    "print(\"R2 linear regression\", R2lr)\n",
    "print(\"RMSE test linear regression\", RMSE_test_lr)\n",
    "print(\"q2 external linear regression\", q2lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train, y_train)\n",
    "train_score = lasso.score(X_train, y_train)\n",
    "test_score = lasso.score(X_test, y_test)\n",
    "opt_alpha = lasso.alpha_\n",
    "\n",
    "coeff = lasso.coef_\n",
    "intercept_lasso = lasso.intercept_\n",
    "coeff_used = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "#train\n",
    "y_hat_lasso = lasso.predict(X_train)\n",
    "RMSE_lasso = sqrt(mean_squared_error(y_train, y_hat_lasso))\n",
    "r_lasso = np.corrcoef(y_train, y_hat_lasso)\n",
    "R2_lasso = r_lasso[0][1]**2\n",
    "\n",
    "# test\n",
    "predictions = pd.DataFrame(lasso.predict(X_test), index=X_test.index, columns=['Prediction'])\n",
    "q2_lasso = q2ext(y_test, predictions, y_train)\n",
    "RMSE_test_lasso = sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(\"optimum alpha: \", opt_alpha)\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "print(\"RMSE lasso\", RMSE_lasso)\n",
    "print(\"R2 lasso\", R2_lasso)\n",
    "print(\"RMSE test lasso\", RMSE_test_lasso)\n",
    "print(\"q2 external lasso\", q2_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select primary comprative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "if RMSE_test_lasso <= RMSE_test_lr:\n",
    "    selected_base_model = \"lasso\"\n",
    "    base_model = lasso\n",
    "    optRMSE_test = RMSE_test_lasso\n",
    "    MAE_in_test = st.mean(abs(predictions.squeeze() - y_test))\n",
    "    REG_in = sum(abs(lasso.coef_))\n",
    "    selected_variables = coeff\n",
    "    intercept_base = intercept_lasso\n",
    "    R2_base = R2_lasso\n",
    "    RMSE_base = RMSE_lasso\n",
    "    q2_base = q2_lasso\n",
    "    RMSE_test_base = RMSE_test_lasso\n",
    "    y_hat_base = y_hat_lasso\n",
    "    y_hat_test_base = lasso.predict(X_test)\n",
    "# MLR\n",
    "else:\n",
    "    selected_base_model = \"MLR\"\n",
    "    base_model = lr\n",
    "    optRMSE_test = RMSE_test_lr\n",
    "    MAE_in_test = st.mean(abs(predictionsLR.squeeze() - y_test))\n",
    "    REG_in = sum(abs(coeffLR))\n",
    "    selected_variables = coeffLR\n",
    "    intercept_base = interceptLR\n",
    "    R2_base = R2lr\n",
    "    RMSE_base = RMSE_lr\n",
    "    q2_base = q2lr\n",
    "    RMSE_test_base = RMSE_test_lr\n",
    "    y_hat_base = y_hat_lr\n",
    "    y_hat_test_base = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main deimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# parameters\n",
    "lREG_min = 0.001\n",
    "lREG_max = 0.07 \n",
    "step = 0.001\n",
    "U = 10\n",
    "U2 = abs(sum(y_test))\n",
    "beta = 0.05\n",
    "epsilon = 0.05\n",
    "\n",
    "start_parall = time.process_time()\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `deimos_regions()`\n",
    "results = [pool.apply(deimos_regions, args = (lREG, MAE_in_test, REG_in, epsilon, beta, U, U2, features, samples_train, X_train, y_train, X_test, y_test, y_hat_base, y_hat_test_base)) for lREG in np.arange(lREG_min, lREG_max, step)]\n",
    "\n",
    "# Step 3: Close\n",
    "pool.close() \n",
    "\n",
    "end_parall = time.process_time()\n",
    "\n",
    "print(\"Execution CPU time [s]:\", (end_parall-start_parall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optFound = 0\n",
    "\n",
    "# save results from each lREG\n",
    "finalregions_lREG = []\n",
    "bestYr_lREG = []\n",
    "bestWrf_lREG = []\n",
    "bestBr_lREG = []\n",
    "bestFrs_lREG = []\n",
    "bestREG_lREG = []\n",
    "bestMAE_lREG = []\n",
    "bestPred_lREG = []\n",
    "bestEs_lREG = []\n",
    "y_hat_lREG = []\n",
    "best_z_lREG = []\n",
    "best_correctly_assigned_lREG = []\n",
    "bestPs_test_lREG = []\n",
    "RMSE_test_lREG = []\n",
    "y_hat_test_lREG = []\n",
    "test_idx_lREG = []\n",
    "bestcentroids_lREG = []\n",
    "bestvar_lREG = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    finalregions_lREG.append(results[i][0])\n",
    "    bestYr_lREG.append(results[i][1])\n",
    "    bestWrf_lREG.append(results[i][2])\n",
    "    bestBr_lREG.append(results[i][3])\n",
    "    bestFrs_lREG.append(results[i][4])\n",
    "    bestREG_lREG.append(results[i][5])\n",
    "    bestMAE_lREG.append(results[i][6])\n",
    "    bestPred_lREG.append(results[i][7])\n",
    "    bestEs_lREG.append(results[i][8])\n",
    "    y_hat_lREG.append(results[i][9])\n",
    "    best_z_lREG.append(results[i][10])\n",
    "    best_correctly_assigned_lREG.append(results[i][11])\n",
    "    bestPs_test_lREG.append(results[i][12])\n",
    "    RMSE_test_lREG.append(results[i][13])\n",
    "    y_hat_test_lREG.append(results[i][14])\n",
    "    test_idx_lREG.append(results[i][15])\n",
    "    bestcentroids_lREG.append(results[i][16])\n",
    "    bestvar_lREG.append(results[i][17])\n",
    "\n",
    "for i in range(len(finalregions_lREG)):\n",
    "    if finalregions_lREG[i] >= 2:\n",
    "        possible_opt = RMSE_test_lREG[i]\n",
    "        if possible_opt <= optRMSE_test:\n",
    "            optFound = 1  # Optimal grouping in regions found\n",
    "            optRMSE_test = possible_opt\n",
    "            opt_position = RMSE_test_lREG.index(possible_opt)\n",
    "            optlREG = lREG_min + opt_position * step\n",
    "            optregions = finalregions_lREG[opt_position]\n",
    "            optcentroids = bestcentroids_lREG[opt_position]\n",
    "            opt_common_variables = bestvar_lREG[opt_position]\n",
    "\n",
    "            optYr = bestYr_lREG[opt_position]\n",
    "            optWrf = bestWrf_lREG[opt_position]\n",
    "            optBr = bestBr_lREG[opt_position]\n",
    "            optFrs = bestFrs_lREG[opt_position]\n",
    "            optREG = bestREG_lREG[opt_position]\n",
    "            optMAE = bestMAE_lREG[opt_position]\n",
    "            optPred = bestPred_lREG[opt_position]\n",
    "            optz = best_z_lREG[opt_position]\n",
    "            optEs = bestEs_lREG[opt_position]\n",
    "            opt_y_hat = y_hat_lREG[opt_position]\n",
    "            opt_correctly_assigned = best_correctly_assigned_lREG[opt_position]\n",
    "\n",
    "            optPs_test = bestPs_test_lREG[opt_position]\n",
    "            opt_y_hat_test = y_hat_test_lREG[opt_position]\n",
    "            optTest_idx = test_idx_lREG[opt_position]\n",
    "            optPs_test = bestPs_test_lREG[opt_position]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:        \n",
    "    # Training statistics\n",
    "    # R2 & RMSE in regions\n",
    "    optR2_re = []\n",
    "    optRMSE_re = []\n",
    "    y_train_re = []\n",
    "    Ps = pd.DataFrame(optPred)*pd.DataFrame(optFrs)\n",
    "    for re in range(optregions):\n",
    "        if sum(optFrs[re]) <= 1:\n",
    "            optR2_re.append(np.nan)\n",
    "            optRMSE_re.append(np.nan)\n",
    "        else:\n",
    "            flag = pd.DataFrame(optFrs).iloc[re,] == 1\n",
    "            pos = np.flatnonzero(flag)  # position of samples\n",
    "            y_train_re.append(y_train.iloc[pos])\n",
    "            y_hat_re = Ps.iloc[re].iloc[pos]\n",
    "            r_re = np.corrcoef(y_train_re[re], y_hat_re)\n",
    "            optR2_re.append(r_re[0][1] ** 2)\n",
    "            optRMSE_re.append(sqrt(mean_squared_error(y_train_re[re], y_hat_re)))\n",
    "            del y_hat_re, r_re\n",
    "                \n",
    "    # R2 training\n",
    "    r = np.corrcoef(y_train, opt_y_hat)\n",
    "    optR2 = r[0][1]**2\n",
    "\n",
    "    # RMSE\n",
    "    optRMSE = sqrt(mean_squared_error(y_train, opt_y_hat))\n",
    "        \n",
    "    #Test statistics\n",
    "    # q2 test\n",
    "    optq2 = q2ext(y_test, opt_y_hat_test, y_train)\n",
    "        \n",
    "    # q2 & RMSE in regions\n",
    "    optq2_re = []\n",
    "    optRMSE_re = []\n",
    "    for re in range(optregions):\n",
    "        if sum(optTest_idx[re]) < 1:\n",
    "            optq2_re.append(np.nan)\n",
    "            optRMSE_re.append(np.nan)\n",
    "        else:\n",
    "            flag = pd.DataFrame(optTest_idx).iloc[re,] == 1\n",
    "            pos = np.flatnonzero(flag)  # position of samples\n",
    "            y_test_re = y_test.iloc[pos]\n",
    "            y_test_hat_re = optPs_test.iloc[re].iloc[pos]\n",
    "            y_train_re = y_train.iloc[pos]\n",
    "            optq2_re.append(q2ext(y_test_re, y_test_hat_re, y_train_re))\n",
    "            optRMSE_re.append(sqrt(mean_squared_error(y_test_re, y_test_hat_re)))\n",
    "            del y_test_re, y_test_hat_re   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    group_train = []\n",
    "    for i in range(samples_train):\n",
    "        for re in range(optregions):\n",
    "            if optFrs[re][i] == 1:\n",
    "                group_train.append((\"region\"+str(re)))\n",
    "\n",
    "    group_test = []\n",
    "    for i in range(samples_test):\n",
    "        for re in range(optregions):\n",
    "            if optTest_idx[re][i] == 1:\n",
    "                group_test.append((\"region\"+str(re)))\n",
    "\n",
    "    group_train = pd.DataFrame(group_train, index = X_train.index)\n",
    "    group_test = pd.DataFrame(group_test, index = X_test.index)\n",
    "    \n",
    "else:\n",
    "    print(\"No optimal solution found-no possible grouping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_selected = []\n",
    "if optFound == 1:\n",
    "    selINregion = []\n",
    "    for re in range(optregions):\n",
    "        selected = X.columns[[optWrf[re][i]>0 for i in range(len(optWrf[1]))]]\n",
    "        print(\"Variables in region\", re, selected)\n",
    "        selINregion.append(len(selected))\n",
    "        for i in selected:\n",
    "            if i not in total_selected:\n",
    "                total_selected.append(i)\n",
    "    print('# variables per region', selINregion)\n",
    "    print('total variables', len(total_selected))\n",
    "else:\n",
    "    selected =  X.columns[[selected_variables[i]!=0 for i in range(len(selected_variables))]]\n",
    "    for i in selected:\n",
    "        if i not in total_selected:\n",
    "            total_selected.append(i)\n",
    "    print('total variables', len(total_selected))\n",
    "    print(\"Variables\", selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples in regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    trainINregions = []\n",
    "    testINregions = []\n",
    "    for re in range(optregions):\n",
    "        trainINregions.append(len(X_train.index[(np.where(optFrs[re]))]))\n",
    "        testINregions.append(len(X_test.index[(np.where(optTest_idx[re]))]))\n",
    "        \n",
    "    print('train samples per region', trainINregions)\n",
    "    print('test samples per region', testINregions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    print(\"lambda optimal: \", optlREG)\n",
    "    print(\"Correctly assigned training samples in clusterig\", sum(opt_correctly_assigned.iloc[0]), \"out of\", samples_train)\n",
    "    print(\"train-RMSE optimal: \", optRMSE)\n",
    "    print(\"train-RMSE optimal per region: \", optRMSE_re)\n",
    "    print(\"R2 optimal: \", optR2)\n",
    "    print(\"R2 optimal per region: \", optR2_re)\n",
    "else:\n",
    "    print(\"Results for one region \", selected_base_model)\n",
    "    print(\"train-RMSE: \", RMSE_base)\n",
    "    print(\"R2: \", R2_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    print(\"samples in regions\")\n",
    "    for re in range(optregions):\n",
    "        print(\"region\", re)\n",
    "        print(X_train.index[(np.where(optFrs[re]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    r_test = np.corrcoef(y_test, opt_y_hat_test)\n",
    "    r2_test = r_test[0][1]**2\n",
    "    print(\"test-RMSE optimal: \", optRMSE_test)\n",
    "    print(\"test-RMSE per region: \", optRMSE_re)\n",
    "    print(\"q2 optimal: \", optq2)\n",
    "    print(\"q2 per region: \", optq2_re)\n",
    "    print(\"r2 test: \", r2_test)\n",
    "    \n",
    "else:\n",
    "    r_test = np.corrcoef(y_test, y_hat_test_base)\n",
    "    r2_test = r_test[0][1]**2\n",
    "    print(\"Results for one region \", selected_base_model)\n",
    "    print(\"test-RMSE: \", RMSE_test_base)\n",
    "    print(\"q2: \", q2_base)\n",
    "    print(\"r2 test: \", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    column_2_train = pd.DataFrame(np.array(opt_y_hat), index=X_train.index, columns=['Prediction'])\n",
    "else:\n",
    "    column_2_train = pd.DataFrame(y_hat_base, index=X_train.index, columns=['Prediction'])\n",
    "\n",
    "pd.concat([y_train, column_2_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final predictions table\n",
    "if optFound == 1:\n",
    "    column_2 = pd.DataFrame(np.array(opt_y_hat_test), index=X_test.index, columns=['Prediction'])\n",
    "    print(\"samples in regions\")\n",
    "    for re in range(optregions):\n",
    "        print(\"region\", re)\n",
    "        print(X_test.index[(np.where(optTest_idx[re]))])\n",
    "else:\n",
    "    column_2 = pd.DataFrame(y_hat_test_base, index=X_test.index, columns=['Prediction'])\n",
    "    \n",
    "final_table = pd.concat([y_test, column_2], axis=1)\n",
    "print(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final predictions table (real values, not normalized)\n",
    "y_test_real = y_test*(y.max() - y.min())+y.min()\n",
    "y_train_real = y_train*(y.max() - y.min())+y.min()\n",
    "if optFound == 1:\n",
    "    opt_y_hat_test_real = opt_y_hat_test*(y.max() - y.min())+y.min()\n",
    "    column_2_real = pd.DataFrame(np.array(opt_y_hat_test_real), index=X_test.index, columns=['Prediction'])\n",
    "    q2_real = q2ext(y_test_real, opt_y_hat_test_real, y_train_real)\n",
    "else:\n",
    "    y_hat_test_base_real = y_hat_test_base*(y.max() - y.min())+y.min()\n",
    "    column_2_real = pd.DataFrame(y_hat_test_base_real, index=X_test.index, columns=['Prediction'])\n",
    "    q2_real = q2ext(y_test_real, y_hat_test_base_real, y_train_real)\n",
    "    \n",
    "    \n",
    "final_table = pd.concat([y_test_real, column_2_real], axis=1)\n",
    "print(final_table)\n",
    "print(\"q2 real\", q2_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    print(\"optYr\", optYr)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    for re in range(optregions):\n",
    "        print(\"region\", re)\n",
    "        print(\"samples\", np.where(optTest_idx[re]))\n",
    "        print(\"y_test\", y_test.iloc[np.where(optTest_idx[re])])\n",
    "        print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    print(\"regions: \", optregions)\n",
    "    print(\"centroids\", optcentroids)\n",
    "    print(\"coefficients\", optWrf)\n",
    "    print(\"intercept: \", optBr)\n",
    "else:\n",
    "    print(\"final model: \", selected_base_model)\n",
    "    print(\"coefficients: \",selected_variables)\n",
    "    print(\"intercept: \", intercept_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    for re in range(optregions):\n",
    "        plt.scatter(y_train.iloc[np.where(optFrs[re])], opt_y_hat[np.where(optFrs[re])], c=\"r\", alpha=0.5, label=\"train\")\n",
    "        plt.scatter(y_test.iloc[np.where(optTest_idx[re])], opt_y_hat_test.iloc[np.where(optTest_idx[re])], c=\"g\", alpha=0.5, label=\"test\")\n",
    "        plt.xlabel(\"Experimental value\")\n",
    "        plt.ylabel(\"Predicted value\")\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "else:\n",
    "    plt.scatter(y_train, y_hat_base, c=\"r\", alpha=0.5, label=\"train\")\n",
    "    plt.scatter(y_test, y_hat_test_base, c=\"g\", alpha=0.5, label=\"test\")\n",
    "    plt.xlabel(\"Experimental value\")\n",
    "    plt.ylabel(\"Predicted value\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optFound == 1:\n",
    "    fig, axs = plt.subplots(1, optregions)\n",
    "    for re in range(optregions):\n",
    "            axs[re].scatter(y_train.iloc[np.where(optFrs[re])], opt_y_hat[np.where(optFrs[re])], c=\"r\", alpha=0.5,\n",
    "                            label=\"train\")\n",
    "            axs[re].scatter(y_test.iloc[np.where(optTest_idx[re])], opt_y_hat_test.iloc[np.where(optTest_idx[re])],\n",
    "                            c=\"g\", alpha=0.5, label=\"test\")\n",
    "            axs[re].set(xlabel=\"Experimental value\", ylabel=\"Predicted value\")\n",
    "    fig.legend(loc='upper left')\n",
    "    fig.set_size_inches(15.5, 6.5, forward=True)\n",
    "    fig.savefig('finalplot.svg')\n",
    "else:\n",
    "    fig = plt.subplot()\n",
    "    fig.scatter(y_train, y_hat_base, c=\"r\", alpha=0.5, label=\"train\")\n",
    "    fig.scatter(y_test, y_hat_test_base, c=\"g\", alpha=0.5, label=\"test\")\n",
    "    fig.set(xlabel=\"Experimental value\", ylabel=\"Predicted value\")\n",
    "    fig.legend(loc='upper left')\n",
    "    fig.set_size_inches(15.5, 6.5, forward=True)\n",
    "    plt.savefig('finalplot.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "\n",
    "print(\"Execution (wall) time [min]:\", (end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_CPU = time.process_time()\n",
    "\n",
    "print(\"Execution CPU time [s]:\", (end_CPU-start_CPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with untested samples\n",
    "data_file_untested = \"C:/Users/Dimitra/untested.csv\"\n",
    "data_untested = pd.read_csv(data_file_untested, header=0, sep=\";\", index_col=0)\n",
    "\n",
    "# Scaling\n",
    "X_untested_scaled = (data_untested - X.min()) / (X.max() - X.min())\n",
    "\n",
    "if optFound == 1:\n",
    "    from deimos_final_model import deimos_1D_model\n",
    "\n",
    "    y_hat_untested, untested_idx = deimos_1D_model(optcentroids, opt_common_variables, optregions, X_untested_scaled, optWrf, optBr)\n",
    "    y_hat_untested = pd.DataFrame(np.array(y_hat_untested), index=data_untested.index, columns=['Prediction'])\n",
    "    \n",
    "    print(\"samples in regions\")\n",
    "    for re in range(optregions):\n",
    "        print(\"region\", re)\n",
    "        print(data_untested.index[(np.where(untested_idx[re]))])\n",
    "else:\n",
    "    y_hat_untested = pd.DataFrame(base_model.predict(X_untested_scaled), index=data_untested.index, columns=['Prediction'])\n",
    "\n",
    "# Applicability domain\n",
    "domain = []\n",
    "for i in range(len(X_untested_scaled)):\n",
    "    flag = 0\n",
    "    for j in range(len(X_untested_scaled.columns)):\n",
    "        if (X_untested_scaled.iloc[1,j]<0) or (X_untested_scaled.iloc[1,j]>1):\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        domain.append(\"unreliable\")\n",
    "    else:\n",
    "        domain.append(\"reliable\")\n",
    "\n",
    "domain = pd.DataFrame(np.array(domain), index=data_untested.index, columns=['Applicability'])\n",
    "\n",
    "final = pd.concat([y_hat_untested, domain], axis=1)\n",
    "\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
